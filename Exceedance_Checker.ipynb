{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "05afe37cf80baa6bd7a012133a488d4e6ff801e719c05085292ea8d35995f051"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import pandas as pd\r\n",
    "\"\"\"\r\n",
    "This workbook will create two items:\r\n",
    "     1 - It will create a running summary file of the maximum values of ESL exceedances per analysis\r\n",
    "     2 - It will create an exclamation mark delimited file that can be read by the program \"Create_Exceed_Plotfile.py\" to be converted into a plot file.     \r\n",
    "User will have to enter the ESL value threshold. See \"ESL\" variable declaration below.\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "#TASK 1 - INITIATE THE VARIABLES FOR THIS PROCEDURE\r\n",
    "#MAXIFILE = \"\\\\WEFS02\\Data\\Clients\\Buckeye Texas Hub LLC\\BUC14868-Alteration, SB1126, Modeling-Permit 106594\\AMODEL\\01 - Model Output\\Naphtha_WorstCase.X01_01\"\r\n",
    "#            \\WEFS02\\Data\\Clients\\Buckeye Texas Hub LLC\\BUC14868-Alteration, SB1126, Modeling-Permit 106594\\AMODEL\u0001 - Model Output\\Naphtha_WorstCase.X01_01\r\n",
    "MAXIFILE = 'Permitted_EO_Refined.X01' #TODO Can we make this a list to cycle through?\r\n",
    "Output_Sum_File = 'Permitted_EO_Refined - Exceed Summary.txt'\r\n",
    "Output_Max_File = 'Permitted_EO_Refined_1xESL.X01'\r\n",
    "ESL = 20\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "#TASK 2 - READ IN THE AERMOD EXCEEDANCE FILE (\"MAXIFILE\", \"*.X01\"). Skip the header rows. Set the column headers to something meaningful.\r\n",
    " \r\n",
    "df = pd.read_csv(MAXIFILE,delim_whitespace=True,skiprows=7)\r\n",
    "df.columns = ['Avg Time','Source Group','Date','UTME','UTMN','Elev','Hill','Flagpole Height','Conc']\r\n",
    "\r\n",
    "#print(df.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "#TASK 3 - SORT THE DATASET BY UNIQUE UTME-UTMN PAIRS AND CREATE NEW COLUMN OF COMBINED COORDINATES\r\n",
    "df.sort_values(by=['UTME', 'UTMN'],inplace=True) \r\n",
    "#x = df['UTME'].unique() # creates a list of unique UTME values\r\n",
    "#y = df['UTMN'].unique() # creates a list of unique UTMN values\r\n",
    "df['UTME_UTMN'] = df['UTME'].astype(str)+\"_\"+df['UTMN'].astype(str)\r\n",
    "\r\n",
    "#print(df.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# CREATE NEW COLUMNS FOR 2X, 4X, and 10X within the original dataframe. This will fill with 1s and 0s\r\n",
    "df['2xESL']  = df['Conc']>=ESL*2\r\n",
    "df['4xESL']  = df['Conc']>=ESL*4\r\n",
    "df['10xESL'] = df['Conc']>=ESL*10\r\n",
    "\r\n",
    "print(df.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       Avg Time Source Group      Date      UTME       UTMN  Elev  Hill  \\\n",
      "238           1          ALL  16011301  409446.0  3315779.0  3.61  3.61   \n",
      "239           1          ALL  16011301  409471.0  3315754.0  3.61  3.61   \n",
      "240           1          ALL  16011301  409471.0  3315779.0  3.64  3.64   \n",
      "10724         1          ALL  16102223  409471.0  3315779.0  3.64  3.64   \n",
      "241           1          ALL  16011301  409471.0  3315804.0  3.68  3.68   \n",
      "\n",
      "       Flagpole Height      Conc           UTME_UTMN  2xESL  4xESL  10xESL  \n",
      "238                0.0  20.00842  409446.0_3315779.0  False  False   False  \n",
      "239                0.0  20.81941  409471.0_3315754.0  False  False   False  \n",
      "240                0.0  21.14043  409471.0_3315779.0  False  False   False  \n",
      "10724              0.0  20.79348  409471.0_3315779.0  False  False   False  \n",
      "241                0.0  20.77986  409471.0_3315804.0  False  False   False  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# REPLACE 1s and 0s with TRUE and FALSE\r\n",
    "df['2xESL'].replace({True:1,False:0},inplace=True)\r\n",
    "df['4xESL'].replace({True:1,False:0},inplace=True)\r\n",
    "df['10xESL'].replace({True:1,False:0},inplace=True)\r\n",
    "\r\n",
    "print(df.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       Avg Time Source Group      Date      UTME       UTMN  Elev  Hill  \\\n",
      "238           1          ALL  16011301  409446.0  3315779.0  3.61  3.61   \n",
      "239           1          ALL  16011301  409471.0  3315754.0  3.61  3.61   \n",
      "240           1          ALL  16011301  409471.0  3315779.0  3.64  3.64   \n",
      "10724         1          ALL  16102223  409471.0  3315779.0  3.64  3.64   \n",
      "241           1          ALL  16011301  409471.0  3315804.0  3.68  3.68   \n",
      "\n",
      "       Flagpole Height      Conc           UTME_UTMN  2xESL 4xESL 10xESL  \n",
      "238                0.0  20.00842  409446.0_3315779.0      0     0      0  \n",
      "239                0.0  20.81941  409471.0_3315754.0      0     0      0  \n",
      "240                0.0  21.14043  409471.0_3315779.0      0     0      0  \n",
      "10724              0.0  20.79348  409471.0_3315779.0      0     0      0  \n",
      "241                0.0  20.77986  409471.0_3315804.0      0     0      0  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "#TASK 4 - CREATE NEW DATAFRAME 'DFESL'. COUNT THE TOTAL NUMBER OF TIMES THE CONC AT THAT UTME_UTMN EXCEEDS THE ESL LEVEL\r\n",
    "dfESL = pd.DataFrame(columns=['UTMs','1xESL','2xESL','4xESL','10xESL','SRCGROUP'])\r\n",
    "dfESL['UTMs'] = df['UTME_UTMN'].unique()\r\n",
    "dfESL['SRCGROUP'] = 'ALL'   #TODO <====  replace this hardcoded value with the value from df['Source Group'] ******\r\n",
    "dfESL.set_index(dfESL['UTMs'],inplace=True)\r\n",
    "#dfESL.drop(columns = 'UTMs',inplace=True)\r\n",
    "\r\n",
    "print(dfESL.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                  UTMs 1xESL 2xESL 4xESL 10xESL SRCGROUP\n",
      "UTMs                                                                    \n",
      "409446.0_3315779.0  409446.0_3315779.0   NaN   NaN   NaN    NaN      ALL\n",
      "409471.0_3315754.0  409471.0_3315754.0   NaN   NaN   NaN    NaN      ALL\n",
      "409471.0_3315779.0  409471.0_3315779.0   NaN   NaN   NaN    NaN      ALL\n",
      "409471.0_3315804.0  409471.0_3315804.0   NaN   NaN   NaN    NaN      ALL\n",
      "409471.0_3315829.0  409471.0_3315829.0   NaN   NaN   NaN    NaN      ALL\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#TASK 5 - CYCLE THROUGH EACH UTM. CREATE A FILTER TO ONLY LOOK AT THAT INDIVIDUAL VALUE IN THE ORIGINAL DATAFRAME, AND COUNT THE NUMBER OF ENTRIES PER UTM COORDINATE PAIR.\r\n",
    "\r\n",
    "for utm in dfESL['UTMs']:\r\n",
    "    #print(utm)\r\n",
    "    filt = (df['UTME_UTMN'] == utm)\r\n",
    "    #print(df[filt])\r\n",
    "    val = df[filt]['Conc'].count()\r\n",
    "    #print(val, utm)\r\n",
    "    dfESL.loc[utm,'1xESL']  = val\r\n",
    "    #print(dfESL.loc[utm,'1xESL'])\r\n",
    "    \r\n",
    "    dfESL.loc[utm,'2xESL']  = df.loc[filt,'2xESL'].sum()\r\n",
    "    dfESL.loc[utm,'4xESL']  = df.loc[filt,'4xESL'].sum()\r\n",
    "    dfESL.loc[utm,'10xESL'] = df.loc[filt,'10xESL'].sum()\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "#This reports the max of each ESL-exceeding columns\r\n",
    "print('Max # Hours above 1xESL :',dfESL['1xESL'].max())\r\n",
    "print('Max # Hours above 2xESL :',dfESL['2xESL'].max())\r\n",
    "print('Max # Hours above 4xESL :',dfESL['4xESL'].max())\r\n",
    "print('Max # Hours above 10xESL :',dfESL['10xESL'].max())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Max # Hours above 1xESL : 119\n",
      "Max # Hours above 2xESL : 26\n",
      "Max # Hours above 4xESL : 0\n",
      "Max # Hours above 10xESL : 0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "#You can use this to report specific UTM locations (such as GLCmax)\r\n",
    "GLCMAX = \"410332.29_3315865.4\"\r\n",
    "print('\\n*********\\nMax # Hours at GLCmax \\n*********\\n',dfESL.loc[GLCMAX])\r\n",
    "\r\n",
    "GLCNI = \"410467.31_3314696.15\"\r\n",
    "try: \r\n",
    "    print('\\n*********\\nMax # Hours at GLCni \\n*********\\n',dfESL.loc[GLCNI])\r\n",
    "except KeyError: #there may not be any exceeding concentrations at the GLCni\r\n",
    "    pass\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "*********\n",
      "Max # Hours at GLCmax \n",
      "*********\n",
      " UTMs        410332.29_3315865.4\n",
      "1xESL                       113\n",
      "2xESL                        21\n",
      "4xESL                         0\n",
      "10xESL                        0\n",
      "SRCGROUP                    ALL\n",
      "Name: 410332.29_3315865.4, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "#TASK 6 - WRITE TO A NEW SUMMARY TEXT FILE WITH THE UTMS & ELEVATIONS OF NEW AOI DATAFRAME\r\n",
    "# Need to remove the index column at the front and replace with \"   DISCCART\"\r\n",
    "# Need to write in the Receptor Grid acceptable formatting?\r\n",
    "# Need to change the delimiter from comma (default) to space character.\r\n",
    "\r\n",
    "with open(Output_Sum_File,\"a\") as file1:\r\n",
    "    file1.write('* * * * * * * * * * * * *\\n')\r\n",
    "    file1.write('File Name: '+MAXIFILE+'\\n')\r\n",
    "    file1.write('Max # Hours above 1xESL  :'+dfESL['1xESL'].max().astype(str)+'\\n')\r\n",
    "    file1.write('Max # Hours above 2xESL  :'+dfESL['2xESL'].max().astype(str)+'\\n')\r\n",
    "    \r\n",
    "    #file1.write('Max # Hours above 4xESL  :'+dfESL['4xESL'].max().astype(str)+'\\n')\r\n",
    "    file1.write('Max # Hours above 4xESL  :')\r\n",
    "    file1.write(str(dfESL['4xESL'].max()))\r\n",
    "    file1.write('\\n')\r\n",
    "    #file1.write('Max # Hours above 4xESL  :'+dfESL['4xESL'].max().astype(str)+'\\n') # NOTICE. this only works for \"numpy.int64\" type. When this value is 0, it comes back as \"int\" type\r\n",
    "    # The following two lines are used when the value is \"int\" type. Notice the difference between \"astype(str)\" and \"str()\"\r\n",
    "    file1.write('Max # Hours above 10xESL :')\r\n",
    "    file1.write(str(dfESL['10xESL'].max()))\r\n",
    "    #print(type(dfESL['2xESL'].max()))  \r\n",
    "    #print(type(dfESL['4xESL'].max()))\r\n",
    "    #print(type(dfESL['10xESL'].max()))\r\n",
    "    file1.write('\\n')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "#TASK 7 - WRITE TO A NEW EXCEEDANCE FILE IN THE SAME FORMAT AS AERMOD'S \"exceedance.plt\". THIS IS DIFFERENT FROM AERMOD'S OUTPUT X01 FILE\r\n",
    "# Need to remove the index column at the front and replace with \"   DISCCART\"\r\n",
    "# Need to write in the Receptor Grid acceptable formatting?\r\n",
    "# Need to change the delimiter from comma (default) to space character.\r\n",
    "\r\n",
    "dfExceed = dfESL.copy()\r\n",
    "dfExceed.drop(columns=['2xESL','4xESL','10xESL'],inplace=True)\r\n",
    "dfExceed.to_csv(Output_Max_File,index=False,sep='!')\r\n",
    "#dfESL['UTM','2xESL','SRCGROUP'].to_csv(Output_Max_File,index=False,sep=' ')\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#with open(Output_Max_File,\"w\") as file1:\r\n",
    "#    file1.write('*      X             Y         COUNT-CONC    ZELEV    ZHILL    ZFLAG    AVE     GRP  \\n')\r\n",
    "#    file1.write('*_____________ _____________ _____________ ________ ________ ________ ______ ________\\n')\r\n",
    "#    for index, row in df.iteritems():\r\n",
    "#        #print('row',row)\r\n",
    "#        print(df.loc[row,'UTME'])\r\n",
    "#        #print(row['UTME'])\r\n",
    "#        break\r\n",
    "        \r\n",
    "#    for utm in dfESL['UTMs']:\r\n",
    "#        break\r\n",
    "#        filt = (df['UTME_UTMN'] == utm)\r\n",
    "#        print(utm)\r\n",
    "#        utme = df.loc[filt]['UTME']\r\n",
    "#        print(utme)\r\n",
    "#        utmn = df.loc[filt]['UTMN']\r\n",
    "#        print(utmn)\r\n",
    "#        \r\n",
    "#        countconc = df.loc[filt,'2xESL'].astype(str)   # <-- CHANGE THIS LEVEL FRO 2xESL to either 4x or 10x IF YOU WANT A DIFFERENT THRESHOLD\r\n",
    "#        print(countconc)\r\n",
    "        \r\n",
    "#        extra = '     0.00     0.00     0.00 1      '\r\n",
    "#        group = df[filt]['Source Group'].astype(str)\r\n",
    "#        print(group)\r\n",
    "#        #file1.write('   '+utm+' '+str(countconc)+' '+extra+' '+str(group)+'\\n')\r\n",
    "#        break\r\n",
    "#        file1.write('   '+str(utme)+' '+str(utmn)+' '+str(countconc)+' '+extra+' '+str(group)+'\\n')\r\n",
    "\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}